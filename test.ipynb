{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from pettingzoo.atari import mario_bros_v3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReplayMemory:\n",
    "\n",
    "    def __init__(self,capacity) -> None:\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.idx = 0\n",
    "    \n",
    "    def toElement(self,state,action,next_state,reward,terminal):\n",
    "        return {'state':state, 'action':action, 'next_state':next_state,'reward':reward,'terminal': 1-int(terminal)}\n",
    "\n",
    "    def fromElement(self,elm):\n",
    "        return elm['state'],elm['action'],elm['next_state'],elm['reward'],elm['terminal']\n",
    "    \n",
    "    def store(self,elm):\n",
    "        if(len(self.memory) < self.capacity):\n",
    "            self.memory += [elm]\n",
    "        else:\n",
    "            self.memory[self.idx] = elm\n",
    "            self.idx = (self.idx + 1) % self.capacity\n",
    "    \n",
    "    def sample(self,batchsize):\n",
    "        indices_to_sample = random.sample(range(len(self.memory)),k = batchsize)\n",
    "\n",
    "        return np.array(self.memory)[indices_to_sample]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def getField(self, memory, name = \"state\"):\n",
    "        ans = []\n",
    "        for i in range(len(memory)):    \n",
    "            ans += [memory[i][name]]\n",
    "        return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Convolution2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNNet:\n",
    "\n",
    "    def __init__(self,height,width,num_frames,num_actions):\n",
    "    \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.num_frames = num_frames\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def build(self):\n",
    "        model = Sequential()\n",
    "        model.add(Convolution2D(16,(8,8),strides = (4,4), activation = 'relu',input_shape=(self.num_frames,self.height,self.width,1)))\n",
    "        model.add(Convolution2D(32,(8,8),strides = (4,4), activation = 'relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(Dense(256,activation='relu'))\n",
    "        model.add(Dense(self.num_actions,activation='linear'))\n",
    "        self.model = model\n",
    "        return self.model\n",
    "\n",
    "    def compile(self,lr):\n",
    "        self.model.compile(optimizer = Adam(lr=lr),loss='mse')\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self,state):\n",
    "        actions = self.model.predict(state)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,height,widht,num_frames,n_actions,epsilon,batch_size,alpha=0.0005,gamma=0.996,epsilon_step=0.00001,epsilon_min=0.01,mem_size=1000000,fname='dqn_model.h5'):\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.n_actions = n_actions\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_step = epsilon_step\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "        self.model_file = fname\n",
    "        self.memory = ReplayMemory(mem_size)\n",
    "        \n",
    "        self.dqnnet = DQNNet(height,widht,num_frames,n_actions)\n",
    "        self.dqnnet.build()\n",
    "        self.dqnnet.compile(alpha)\n",
    "\n",
    "    def choose_action(self,state):\n",
    "\n",
    "        # state = state[np.newaxis,:]\n",
    "\n",
    "        rand = np.random.random()\n",
    "        if(rand < self.epsilon):\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            action = self.dqnnet.predict(state)\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def remember(self,state,action,next_state,reward,done):\n",
    "        self.memory.store(self.memory.toElement(state,action,next_state,reward,done))\n",
    "    \n",
    "    def learn(self):\n",
    "        if(len(self.memory) < self.batch_size):\n",
    "            return\n",
    "        # fill up the memory with random actions\n",
    "\n",
    "        mem_sample = self.memory.sample(self.batch_size)\n",
    "    \n",
    "        state = self.memory.getField(mem_sample,name='state')\n",
    "        action = self.memory.getField(mem_sample,name='action')\n",
    "        next_state = self.memory.getField(mem_sample,name='next_state')\n",
    "        reward = self.memory.getField(mem_sample,name='reward')\n",
    "        terminal = self.memory.getField(mem_sample,name='terminal')\n",
    "\n",
    "        action_indices = action\n",
    "        print('inside learn')\n",
    "\n",
    "        q_eval = self.dqnnet.predict(state)\n",
    "        q_next = self.dqnnet.predict(next_state)\n",
    "\n",
    "        q_target = q_eval.copy()\n",
    "\n",
    "        batch_index = np.arange(self.batch_size, dtype = np.int32)\n",
    "\n",
    "        \n",
    "        q_target[batch_index, action_indices] = reward + self.gamma * np.max(q_next, axis=1)*terminal\n",
    "        \n",
    "        _ = self.dqnnet.model.fit(state,q_target,verbose=0)\n",
    "    \n",
    "        if(self.epsilon > self.epsilon_min):\n",
    "            self.epsilon -= self.epsilon_step\n",
    "\n",
    "    def save_model(self):\n",
    "        self.q_eval.save(self.model_file)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.q_eval = load_model(self.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gym/utils/seeding.py:155: DeprecationWarning: \u001b[33mWARN: Function `create_seed(a, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/gym/utils/seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = mario_bros_v3.env(obs_type = 'grayscale_image')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_step(agent,state,score,name='first_0'):\n",
    "    action = agent.choose_action(np.array(state))\n",
    "    print(action)\n",
    "    reward = env.rewards[name]\n",
    "    done = env.dones[name]\n",
    "    observation = env.observe(name)\n",
    "\n",
    "    old_state = np.array(state.copy())\n",
    "\n",
    "    state.pop(0)\n",
    "    state+=[observation]\n",
    "    score+=reward\n",
    "    agent.remember(old_state,action1,np.array(state),reward,done)\n",
    "    agent.learn()\n",
    "\n",
    "    return agent,state,action,score,done\n",
    "\n",
    "def dont_learn_step(agent,state,score,name='first_0'):\n",
    "    action = agent.choose_action(np.array(state))\n",
    "    print(action)\n",
    "    reward = env.rewards[name]\n",
    "    done = env.dones[name]\n",
    "    observation = env.observe(name)\n",
    "\n",
    "    old_state = np.array(state.copy())\n",
    "\n",
    "    state.pop(0)\n",
    "    state+=[observation]\n",
    "    score+=reward\n",
    "    if(reward!=0):\n",
    "        agent.remember(old_state,action1,np.array(state),reward,done)\n",
    "\n",
    "    return agent,state,action,score,done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 1)\n",
      "4\n",
      "12\n",
      "11\n",
      "0\n",
      "9\n",
      "14\n",
      "15\n",
      "4\n",
      "9\n",
      "9\n",
      "0\n",
      "9\n",
      "0\n",
      "3\n",
      "12\n",
      "6\n",
      "11\n",
      "5\n",
      "16\n",
      "0\n",
      "10\n",
      "1\n",
      "16\n",
      "7\n",
      "9\n",
      "5\n",
      "3\n",
      "1\n",
      "16\n",
      "10\n",
      "0\n",
      "10\n",
      "12\n",
      "6\n",
      "8\n",
      "17\n",
      "13\n",
      "17\n",
      "7\n",
      "2\n",
      "6\n",
      "9\n",
      "5\n",
      "10\n",
      "11\n",
      "12\n",
      "2\n",
      "3\n",
      "10\n",
      "1\n",
      "6\n",
      "15\n",
      "0\n",
      "0\n",
      "11\n",
      "16\n",
      "17\n",
      "3\n",
      "12\n",
      "10\n",
      "2\n",
      "17\n",
      "7\n",
      "7\n",
      "10\n",
      "2\n",
      "15\n",
      "10\n",
      "2\n",
      "10\n",
      "10\n",
      "14\n",
      "17\n",
      "4\n",
      "13\n",
      "9\n",
      "12\n",
      "9\n",
      "15\n",
      "16\n",
      "14\n",
      "2\n",
      "6\n",
      "4\n",
      "6\n",
      "9\n",
      "16\n",
      "11\n",
      "3\n",
      "9\n",
      "1\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "12\n",
      "11\n",
      "15\n",
      "3\n",
      "6\n",
      "5\n",
      "4\n",
      "16\n",
      "13\n",
      "6\n",
      "4\n",
      "5\n",
      "11\n",
      "13\n",
      "17\n",
      "14\n",
      "8\n",
      "7\n",
      "2\n",
      "6\n",
      "12\n",
      "12\n",
      "6\n",
      "10\n",
      "15\n",
      "17\n",
      "5\n",
      "0\n",
      "4\n",
      "14\n",
      "16\n",
      "11\n",
      "5\n",
      "10\n",
      "11\n",
      "3\n",
      "7\n",
      "8\n",
      "7\n",
      "5\n",
      "12\n",
      "13\n",
      "6\n",
      "3\n",
      "14\n",
      "10\n",
      "3\n",
      "12\n",
      "8\n",
      "11\n",
      "2\n",
      "15\n",
      "8\n",
      "5\n",
      "8\n",
      "15\n",
      "14\n",
      "1\n",
      "15\n",
      "7\n",
      "17\n",
      "13\n",
      "5\n",
      "9\n",
      "15\n",
      "4\n",
      "13\n",
      "7\n",
      "7\n",
      "3\n",
      "13\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "10\n",
      "3\n",
      "6\n",
      "14\n",
      "6\n",
      "17\n",
      "1\n",
      "4\n",
      "11\n",
      "0\n",
      "11\n",
      "4\n",
      "11\n",
      "12\n",
      "2\n",
      "16\n",
      "0\n",
      "16\n",
      "12\n",
      "3\n",
      "14\n",
      "6\n",
      "15\n",
      "12\n",
      "4\n",
      "9\n",
      "0\n",
      "0\n",
      "5\n",
      "16\n",
      "5\n",
      "14\n",
      "17\n",
      "1\n",
      "4\n",
      "1\n",
      "6\n",
      "13\n",
      "17\n",
      "2\n",
      "2\n",
      "10\n",
      "0\n",
      "3\n",
      "0\n",
      "9\n",
      "16\n",
      "3\n",
      "13\n",
      "16\n",
      "2\n",
      "12\n",
      "11\n",
      "16\n",
      "3\n",
      "6\n",
      "11\n",
      "13\n",
      "5\n",
      "6\n",
      "12\n",
      "10\n",
      "0\n",
      "15\n",
      "15\n",
      "1\n",
      "11\n",
      "1\n",
      "14\n",
      "16\n",
      "11\n",
      "13\n",
      "7\n",
      "0\n",
      "15\n",
      "14\n",
      "14\n",
      "12\n",
      "13\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "12\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "8\n",
      "2\n",
      "17\n",
      "9\n",
      "5\n",
      "1\n",
      "12\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "2\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "5\n",
      "1\n",
      "16\n",
      "9\n",
      "11\n",
      "13\n",
      "14\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "9\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1\n",
      "9\n",
      "0\n",
      "8\n",
      "14\n",
      "6\n",
      "9\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "12\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "11\n",
      "7\n",
      "6\n",
      "1\n",
      "6\n",
      "3\n",
      "17\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "16\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "2\n",
      "7\n",
      "16\n",
      "0\n",
      "16\n",
      "8\n",
      "5\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "4\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "11\n",
      "15\n",
      "8\n",
      "15\n",
      "8\n",
      "11\n",
      "4\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "17\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "13\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "1\n",
      "13\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "15\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "11\n",
      "5\n",
      "3\n",
      "13\n",
      "11\n",
      "17\n",
      "7\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "0\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "16\n",
      "4\n",
      "15\n",
      "16\n",
      "15\n",
      "17\n",
      "3\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "16\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "16\n",
      "15\n",
      "14\n",
      "7\n",
      "17\n",
      "15\n",
      "0\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "6\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "7\n",
      "0\n",
      "17\n",
      "14\n",
      "8\n",
      "8\n",
      "12\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "14\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "11\n",
      "14\n",
      "13\n",
      "3\n",
      "9\n",
      "0\n",
      "11\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "13\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "9\n",
      "12\n",
      "3\n",
      "5\n",
      "13\n",
      "1\n",
      "11\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "17\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "4\n",
      "9\n",
      "8\n",
      "7\n",
      "2\n",
      "10\n",
      "17\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "4\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "9\n",
      "0\n",
      "11\n",
      "13\n",
      "12\n",
      "8\n",
      "11\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "14\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "9\n",
      "12\n",
      "16\n",
      "17\n",
      "3\n",
      "12\n",
      "1\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "6\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "17\n",
      "14\n",
      "14\n",
      "5\n",
      "13\n",
      "7\n",
      "10\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "11\n",
      "8\n",
      "15\n",
      "11\n",
      "7\n",
      "6\n",
      "5\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "10\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "17\n",
      "14\n",
      "3\n",
      "17\n",
      "16\n",
      "1\n",
      "4\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "2\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "9\n",
      "16\n",
      "16\n",
      "3\n",
      "6\n",
      "4\n",
      "9\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "16\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "15\n",
      "6\n",
      "4\n",
      "17\n",
      "15\n",
      "6\n",
      "0\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "14\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "2\n",
      "9\n",
      "6\n",
      "2\n",
      "11\n",
      "0\n",
      "14\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "16\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "7\n",
      "17\n",
      "14\n",
      "1\n",
      "9\n",
      "16\n",
      "8\n",
      "inside learn\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matheusfranco/Documents/Acadêmica/Computação/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000005?line=23'>24</a>\u001b[0m action2 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000005?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000005?line=26'>27</a>\u001b[0m     agent1,state1,action1,score1,done1 \u001b[39m=\u001b[39m normal_step(agent1,state1,score1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000005?line=27'>28</a>\u001b[0m     agent2,state2,action2,score2,done2 \u001b[39m=\u001b[39m normal_step(agent2,state2,score2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000005?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n",
      "\u001b[1;32m/Users/matheusfranco/Documents/Acadêmica/Computação/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb Cell 7'\u001b[0m in \u001b[0;36mnormal_step\u001b[0;34m(agent, state, score, name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000009?line=11'>12</a>\u001b[0m score\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mreward\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000009?line=12'>13</a>\u001b[0m agent\u001b[39m.\u001b[39mremember(old_state,action1,np\u001b[39m.\u001b[39marray(state),reward,done)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000009?line=13'>14</a>\u001b[0m agent\u001b[39m.\u001b[39;49mlearn()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000009?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m agent,state,action,score,done\n",
      "\u001b[1;32m/Users/matheusfranco/Documents/Acadêmica/Computação/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb Cell 5'\u001b[0m in \u001b[0;36mAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000006?line=45'>46</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minside learn\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000006?line=47'>48</a>\u001b[0m q_eval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdqnnet\u001b[39m.\u001b[39mpredict(state)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000006?line=48'>49</a>\u001b[0m q_next \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdqnnet\u001b[39m.\u001b[39;49mpredict(next_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000006?line=50'>51</a>\u001b[0m q_target \u001b[39m=\u001b[39m q_eval\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000006?line=52'>53</a>\u001b[0m batch_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint32)\n",
      "\u001b[1;32m/Users/matheusfranco/Documents/Acadêmica/Computação/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb Cell 4'\u001b[0m in \u001b[0;36mDQNNet.predict\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000003?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m,state):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000003?line=25'>26</a>\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matheusfranco/Documents/Acade%CC%82mica/Computac%CC%A7a%CC%83o/AASMA/AASMA_Projeto_MarioBros/test2/test.ipynb#ch0000003?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m actions\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "state, r, d, info = env.last()\n",
    "\n",
    "agent1 = Agent(210,160,4,18,1.0,32)\n",
    "agent2 = Agent(210,160,4,18,1.0,32)\n",
    "\n",
    "print(state.shape)\n",
    "\n",
    "score1 = 0\n",
    "score2 = 0\n",
    "state1 = []\n",
    "state2 = []\n",
    "for i in range(4):\n",
    "    o,r,d,i = env.last()\n",
    "    state1+=[o]\n",
    "    score1 += r\n",
    "    env.step(0)\n",
    "    o,r,d,i = env.last()\n",
    "    state2+=[o]\n",
    "    score2+=r\n",
    "    env.step(0)\n",
    "\n",
    "action1 = 0\n",
    "action2 = 0\n",
    "\n",
    "for i in range(100):\n",
    "    agent1,state1,action1,score1,done1 = normal_step(agent1,state1,score1)\n",
    "    agent2,state2,action2,score2,done2 = normal_step(agent2,state2,score2)\n",
    "\n",
    "    for i in range(3):\n",
    "        agent1,state1,action1,score1,done1 = dont_learn_step(agent1,state1,score1)\n",
    "        agent2,state2,action2,score2,done2 = dont_learn_step(agent2,state2,score2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
